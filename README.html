<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>彩虹的情诗</title><meta description="手写数字识别加载数据torchvision datasets 提供了 minist 数据集下载 1234567891011121314train_data &amp;#x3D; dsets.MNIST(    root&amp;#x3D;&amp;#39;.&amp;#x2F;mnist&amp;#x2F;&amp;#39;,    train&amp;#x3D;True,    transform&amp;#x3D;transforms.ToTensor(),    download&amp;#x3D;True,)train_loader &amp;#x3D; Dat"><meta property="og:type" content="blog"><meta property="og:title" content="彩虹的情诗"><meta property="og:url" content="https://blog.adream.win/README.html"><meta property="og:site_name" content="彩虹的情诗"><meta property="og:description" content="手写数字识别加载数据torchvision datasets 提供了 minist 数据集下载 1234567891011121314train_data &amp;#x3D; dsets.MNIST(    root&amp;#x3D;&amp;#39;.&amp;#x2F;mnist&amp;#x2F;&amp;#39;,    train&amp;#x3D;True,    transform&amp;#x3D;transforms.ToTensor(),    download&amp;#x3D;True,)train_loader &amp;#x3D; Dat"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhangxu3486432/zhangxu3486432.github.io/images/20200630232246.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhangxu3486432/zhangxu3486432.github.io/images/20200630233518.png"><meta property="article:published_time" content="2020-07-23T09:18:26.194Z"><meta property="article:modified_time" content="2020-07-23T09:18:26.187Z"><meta property="article:author" content="张旭"><meta property="article:tag" content="web"><meta property="article:tag" content="后端"><meta property="article:tag" content="产品"><meta property="article:tag" content="诗歌"><meta property="article:tag" content="爬虫"><meta property="article:tag" content="docker"><meta property="article:tag" content="大数据"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="论文科研"><meta property="article:tag" content="技术知识"><meta property="article:tag" content="个人博客"><meta property="article:tag" content="记录"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/zhangxu3486432/zhangxu3486432.github.io/images/20200630232246.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.adream.win/README.html"},"headline":"彩虹的情诗","image":["https://cdn.jsdelivr.net/gh/zhangxu3486432/zhangxu3486432.github.io/images/20200630232246.png","https://cdn.jsdelivr.net/gh/zhangxu3486432/zhangxu3486432.github.io/images/20200630233518.png"],"datePublished":"2020-07-23T09:18:26.194Z","dateModified":"2020-07-23T09:18:26.187Z","author":{"@type":"Person","name":"张旭"},"description":"手写数字识别加载数据torchvision datasets 提供了 minist 数据集下载 1234567891011121314train_data &#x3D; dsets.MNIST(    root&#x3D;&#39;.&#x2F;mnist&#x2F;&#39;,    train&#x3D;True,    transform&#x3D;transforms.ToTensor(),    download&#x3D;True,)train_loader &#x3D; Dat"}</script><link rel="canonical" href="https://blog.adream.win/README.html"><link rel="icon" href="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200723204346.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?031fa1be6eb280bf0d68ad002719eb23";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-152046316-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-152046316-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200723204234.svg" alt="彩虹的情诗" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zhangxu3486432/"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile"> </h1><div class="content"><h1 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h1><h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2><p><code>torchvision datasets</code> 提供了 <code>minist</code> 数据集下载</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">train_data = dsets.MNIST(</span><br><span class="line">    root=<span class="string">'./mnist/'</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.ToTensor(),</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_data = dsets.MNIST(root=<span class="string">'./mnist/'</span>, train=<span class="literal">False</span>, transform=transforms.ToTensor())</span><br><span class="line">text_x1 = test_data.data[:<span class="number">2000</span>]</span><br><span class="line">text_x2 = test_data.data[:<span class="number">2000</span>]</span><br><span class="line">test_x = torch.cat((text_x1, text_x2.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)), dim=<span class="number">1</span>) / <span class="number">255.</span></span><br><span class="line">test_y = test_data.targets[:<span class="number">2000</span>]</span><br></pre></td></tr></table></figure>

<h2 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h2><p>使用双向多层 LSTM 对图像进行处理，串联第 n 行，第 n 列的像素作为第 n 个时间步的输入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, n_class, num_layers, dropout, bidirectional)</span>:</span></span><br><span class="line">        super(RNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.rnn = nn.LSTM(</span><br><span class="line">            input_size=input_size,</span><br><span class="line">            hidden_size=hidden_size,</span><br><span class="line">            num_layers=num_layers,</span><br><span class="line">            batch_first=<span class="literal">True</span>,</span><br><span class="line">            dropout=dropout,</span><br><span class="line">            bidirectional=bidirectional,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        L_size = hidden_size * <span class="number">2</span> <span class="keyword">if</span> bidirectional <span class="keyword">else</span> hidden_size</span><br><span class="line">        self.out = nn.Linear(L_size, n_class)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'_flattened'</span>):</span><br><span class="line">            self.rnn.flatten_parameters()</span><br><span class="line">        setattr(self, <span class="string">'_flattened'</span>, <span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># x shape (batch, time_step, input_size)</span></span><br><span class="line">        <span class="comment"># r_out shape (batch, time_step, output_size)</span></span><br><span class="line">        <span class="comment"># h_n shape (n_layers, batch, hidden_size)</span></span><br><span class="line">        <span class="comment"># h_c shape (n_layers, batch, hidden_size)</span></span><br><span class="line">        r_out, (h_n, c_n) = self.rnn(x, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        out = self.out(r_out.mean(<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>损失函数采用的是 <code>CrossEntropyLoss</code>，优化器采用的 <code>Adam</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">model = RNN(</span><br><span class="line">    input_size=INPUT_SIZE,</span><br><span class="line">    hidden_size=hidden,</span><br><span class="line">    n_class=N_CLASS,</span><br><span class="line">    num_layers=num_layers,</span><br><span class="line">    dropout=dropout,</span><br><span class="line">    bidirectional=bidirectional</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters(),</span><br><span class="line">                       lr=lr, weight_decay=weight_decay)</span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br><span class="line">model = nn.DataParallel(model, device_ids=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">model.cuda()</span><br><span class="line">test_x = test_x.cuda()</span><br><span class="line">test_y = test_y.cuda()</span><br><span class="line"></span><br><span class="line">x = []</span><br><span class="line">train_acc_set = []</span><br><span class="line">loss_set = []</span><br><span class="line">test_acc_set = []</span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> b_x, b_y <span class="keyword">in</span> train_loader:</span><br><span class="line">        input1 = b_x.view(<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        input2 = b_x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>).view(<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">        input = torch.cat((input1, input2), dim=<span class="number">1</span>)</span><br><span class="line">        input = input.cuda()</span><br><span class="line">        b_y = b_y.cuda()</span><br><span class="line"></span><br><span class="line">        output = model(input)</span><br><span class="line">        pred_y = torch.max(output, <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">        loss = loss_func(output, b_y)</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            x.append(step)</span><br><span class="line">            train_acc = float((pred_y == b_y).type(torch.int).sum()) / float(len(b_y))</span><br><span class="line">            train_acc_set.append(train_acc)</span><br><span class="line">            loss_set.append(loss.item())</span><br><span class="line">            </span><br><span class="line">            test_output = model(test_x)</span><br><span class="line">            pred_y = torch.max(test_output, <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            test_acc = float((pred_y == test_y).type(torch.int).sum()) / float(len(test_y))</span><br><span class="line">            </span><br><span class="line">            test_acc_set.append(test_acc)</span><br><span class="line">            print(<span class="string">'Epoch: '</span>, epoch, <span class="string">'step: '</span>, step, <span class="string">'| train loss: %.4f'</span> % loss.item(), <span class="string">'| train accuracy: %.2f'</span> % train_acc, <span class="string">'| test accuracy: %.2f'</span> % test_acc)</span><br><span class="line">        </span><br><span class="line">        step += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h2><p>经过 10 个 epochs，最终的结果稳定在 0.97，这表明 LSTM 也有提取并记忆图像特征的能力。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhangxu3486432/zhangxu3486432.github.io/images/20200630232246.png" alt=""></p>
<h1 id="猫狗分类"><a href="#猫狗分类" class="headerlink" title="猫狗分类"></a>猫狗分类</h1><h2 id="加载数据-1"><a href="#加载数据-1" class="headerlink" title="加载数据"></a>加载数据</h2><p>首先对原始数据进行处理，在原始数据中 cat 和 dog 的图片都存放在一个文件夹内，首先将 cat 和 dog 的图片存放在不同的文件夹</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir cat</span><br><span class="line">mkdir dog</span><br><span class="line"></span><br><span class="line">mv cat.*.jpg ./cat</span><br><span class="line">mv dog.*.jpg ./dog</span><br></pre></td></tr></table></figure>

<p>再利用 <code>ImageFolder</code> 函数加载数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">normalize = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">227</span>, <span class="number">227</span>)),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        normalize,</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_dataset = ImageFolder(<span class="string">'/home/zx19/projects/cat_dog/dataset/train/'</span>,transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="number">512</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">validation_dataset = ImageFolder(<span class="string">'/home/zx19/projects/cat_dog/dataset/validation/'</span>,transform=transform)</span><br><span class="line">validationloader = torch.utils.data.DataLoader(validation_dataset, batch_size=<span class="number">500</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2 id="构建网络-1"><a href="#构建网络-1" class="headerlink" title="构建网络"></a>构建网络</h2><p>采用的是 <code>AlexNet</code> 构建的网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes=<span class="number">1000</span>)</span>:</span></span><br><span class="line">        super(AlexNet, self).__init__()</span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">192</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">256</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alexnet</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    model = AlexNet(**kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        state_dict = torch.hub.load_state_dict_from_url(<span class="string">'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth'</span>, progress=progress)</span><br><span class="line">        model.load_state_dict(state_dict)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>在 alexnet 函数的参数 pretrained 为 True 时，将加载 <code>ImageNet</code> 的预训练模型</p>
<h2 id="初始化参数"><a href="#初始化参数" class="headerlink" title="初始化参数"></a>初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init</span><span class="params">(m)</span>:</span></span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">'Conv2d'</span>) != <span class="number">-1</span>:</span><br><span class="line">        m.weight.data.normal_(<span class="number">0.0</span>, <span class="number">0.02</span>)</span><br><span class="line">    <span class="keyword">elif</span> classname.find(<span class="string">'BatchNorm'</span>) != <span class="number">-1</span>:</span><br><span class="line">        m.weight.data.normal_(<span class="number">1.0</span>, <span class="number">0.02</span>)</span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> classname.find(<span class="string">'Linear'</span>) != <span class="number">-1</span>:</span><br><span class="line">        nn.init.xavier_uniform_(m.weight)</span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">model = alexnet(pretrained=<span class="literal">False</span>)</span><br><span class="line">model.classifier[<span class="number">6</span>] = nn.Linear(<span class="number">4096</span>, <span class="number">2</span>)</span><br><span class="line">alexNet = nn.DataParallel(model, device_ids=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">alexNet = alexNet.cuda()</span><br><span class="line">alexNet.apply(weights_init)</span><br></pre></td></tr></table></figure>

<h2 id="训练过程-1"><a href="#训练过程-1" class="headerlink" title="训练过程"></a>训练过程</h2><p>损失函数采用的是 <code>CrossEntropyLoss</code>，优化器使用的是 <code>SGD</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">criterion &#x3D; nn.CrossEntropyLoss()</span><br><span class="line">optimizer &#x3D; optim.SGD(alexNet.parameters(), lr&#x3D;0.01, momentum&#x3D;0.9, weight_decay&#x3D;0.0005)</span><br><span class="line"></span><br><span class="line">epochs &#x3D; 10</span><br><span class="line">train_losses, validation_losses &#x3D; [], []</span><br><span class="line"></span><br><span class="line">loss_step &#x3D; 0</span><br><span class="line"></span><br><span class="line">for e in range(epochs):</span><br><span class="line">    for step, (images,labels) in enumerate(trainloader):</span><br><span class="line">        </span><br><span class="line">        images &#x3D; images.cuda()</span><br><span class="line">        labels &#x3D; labels.cuda()</span><br><span class="line">       </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        outputs &#x3D; alexNet(images)</span><br><span class="line">        loss &#x3D; criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        loss_step +&#x3D; loss.item()</span><br><span class="line">        </span><br><span class="line">        if (step+1)%10&#x3D;&#x3D;0:</span><br><span class="line"></span><br><span class="line">            with torch.no_grad():</span><br><span class="line">                for images, labels in validationloader:</span><br><span class="line">                    images &#x3D; images.cuda()</span><br><span class="line">                    labels &#x3D; labels.cuda()</span><br><span class="line"></span><br><span class="line">                    outputs &#x3D; alexNet(images)</span><br><span class="line">                    validation_loss &#x3D; criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    equals &#x3D; outputs.max(1).indices &#x3D;&#x3D; labels</span><br><span class="line">                    accuracy &#x3D; torch.mean(equals.type(torch.float))</span><br><span class="line">                    </span><br><span class="line">                    break</span><br><span class="line">            train_losses.append(loss.item())</span><br><span class="line">            validation_losses.append(validation_loss)</span><br><span class="line"></span><br><span class="line">            print(&quot;Epoch: &#123;&#125;&#x2F;&#123;&#125;&quot;.format(e+1, epochs),</span><br><span class="line">                  &quot; | Training Loss: &#123;:.3f&#125;&quot;.format(loss.item()),</span><br><span class="line">                  &quot; | Test Loss: &#123;:.3f&#125;&quot;.format(validation_loss.item()),</span><br><span class="line">                  &quot; | Test Accuracy: &#123;:.3f&#125;&quot;.format(accuracy))</span><br></pre></td></tr></table></figure>

<h2 id="实验分析-1"><a href="#实验分析-1" class="headerlink" title="实验分析"></a>实验分析</h2><p><img src="https://cdn.jsdelivr.net/gh/zhangxu3486432/zhangxu3486432.github.io/images/20200630233518.png" alt=""></p>
<p>在经过 10 个 epochs 训练后，准确率到达了 85%。期间 train loss 和 validation loss 都在持续下降，这说明增加 epochs 还有提高准确率的空间。</p>
<h1 id="自动写诗"><a href="#自动写诗" class="headerlink" title="自动写诗"></a>自动写诗</h1><h2 id="加载数据-2"><a href="#加载数据-2" class="headerlink" title="加载数据"></a>加载数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">datas = np.load(<span class="string">"/home/zx19/projects/poem/tang.npz"</span>, allow_pickle=<span class="literal">True</span>)</span><br><span class="line">data = datas[<span class="string">'data'</span>]</span><br><span class="line">index2word = datas[<span class="string">'ix2word'</span>].item()</span><br><span class="line">word2index = datas[<span class="string">'word2ix'</span>].item()</span><br><span class="line"></span><br><span class="line">data = torch.from_numpy(data)</span><br><span class="line">train_loader = DataLoader(data, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h2 id="构建网络-2"><a href="#构建网络-2" class="headerlink" title="构建网络"></a>构建网络</h2><p>使用了多层单向 LSTM 网络进行训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Poem</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embedding_dim, hidden_dim)</span>:</span></span><br><span class="line">        super(Poem, self).__init__()</span><br><span class="line">        self.num_layers = <span class="number">2</span></span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.embeddings = nn.Embedding(vocab_size, embedding_dim) <span class="comment">#vocab_size:就是ix2word这个字典的长度。</span></span><br><span class="line">        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers=self.num_layers,</span><br><span class="line">                            batch_first=<span class="literal">True</span>,dropout=<span class="number">0</span>, bidirectional=<span class="literal">False</span>)</span><br><span class="line">        self.fc1 = nn.Linear(self.hidden_dim,<span class="number">2048</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">2048</span>,<span class="number">4096</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">4096</span>,vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, hidden=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'_flattened'</span>):</span><br><span class="line">            self.lstm.flatten_parameters()</span><br><span class="line">        setattr(self, <span class="string">'_flattened'</span>, <span class="literal">True</span>)</span><br><span class="line">        embeds = self.embeddings(input)  <span class="comment"># [batch, seq_len] =&gt; [batch, seq_len, embed_dim]</span></span><br><span class="line">        batch_size, seq_len = input.size()</span><br><span class="line">        <span class="keyword">if</span> hidden <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            h_0 = input.data.new(self.num_layers*<span class="number">1</span>, batch_size, self.hidden_dim).fill_(<span class="number">0</span>).float()</span><br><span class="line">            c_0 = input.data.new(self.num_layers*<span class="number">1</span>, batch_size, self.hidden_dim).fill_(<span class="number">0</span>).float()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            h_0, c_0 = hidden</span><br><span class="line">        output, hidden = self.lstm(embeds, (h_0, c_0))<span class="comment">#hidden 是h,和c 这两个隐状态</span></span><br><span class="line">        output = torch.tanh(self.fc1(output))</span><br><span class="line">        output = torch.tanh(self.fc2(output))</span><br><span class="line">        output = self.fc3(output)</span><br><span class="line">        output = output.reshape(batch_size * seq_len, <span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> output,hidden</span><br></pre></td></tr></table></figure>

<h2 id="训练过程-2"><a href="#训练过程-2" class="headerlink" title="训练过程"></a>训练过程</h2><p>损失函数使用的是 <code>CrossEntropyLoss</code>，优化器采用的是 <code>Adam</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">5</span></span><br><span class="line">model = Poem(len(word2index), embedding_dim=<span class="number">100</span>, hidden_dim=<span class="number">1024</span>)</span><br><span class="line">model = model.to(device)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.0001</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    train_acc = <span class="number">0</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> step, data <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        inputs, labels = data[:, :<span class="number">-1</span>].to(device).to(torch.long), data[:, <span class="number">1</span>:].to(device).to(torch.long)</span><br><span class="line">        labels = labels.view(<span class="number">-1</span>)</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs,hidden = model(inputs)</span><br><span class="line">        loss = criterion(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        _,pred = outputs.topk(<span class="number">1</span>)</span><br><span class="line">        pred = pred.view(<span class="number">-1</span>)</span><br><span class="line">        acc = (pred==labels).to(torch.float).mean()</span><br><span class="line">        train_acc+=acc</span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (step+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch: &#123;&#125;/&#123;&#125; | Loss: &#123;&#125; | Acc: &#123;&#125;'</span>.format(epoch+<span class="number">1</span>, epochs, train_loss/i, train_acc/i))</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            train_loss = <span class="number">0</span></span><br><span class="line">            train_acc = <span class="number">0</span></span><br><span class="line">    print(<span class="string">'Epoch: &#123;&#125;/&#123;&#125; | Loss: &#123;&#125; | Acc: &#123;&#125;'</span>.format(epoch+<span class="number">1</span>, epochs, train_loss/i, train_acc/i))</span><br></pre></td></tr></table></figure>

<h2 id="预测部分"><a href="#预测部分" class="headerlink" title="预测部分"></a>预测部分</h2><p>在生成下一个预测部分的使用，采样函数使用了 softmax temperature，并不是直接去概率最大的值，temperature 参数控制了随机性，是根据每个词的概率进行采样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(model, start_words, ix2word, word2ix)</span>:</span></span><br><span class="line">    results = list(start_words)</span><br><span class="line">    start_words_len = len(start_words)</span><br><span class="line">    <span class="comment"># 第一个词语是&lt;START&gt;</span></span><br><span class="line">    input = t.Tensor([word2ix[<span class="string">'&lt;START&gt;'</span>]]).view(<span class="number">1</span>, <span class="number">1</span>).long()</span><br><span class="line">    hidden = <span class="literal">None</span></span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(Config.max_gen_len):</span><br><span class="line">            output, hidden = model(input, hidden)</span><br><span class="line">            <span class="comment"># 如果在给定的句首中，input为句首中的下一个字</span></span><br><span class="line">            <span class="keyword">if</span> i &lt; start_words_len:</span><br><span class="line">                w = results[i]</span><br><span class="line">                input = input.data.new([word2ix[w]]).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 否则将output作为下一个input进行</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                top_index = output.data[<span class="number">0</span>].topk(<span class="number">1</span>)[<span class="number">1</span>][<span class="number">0</span>].item()</span><br><span class="line">                w = ix2word[top_index]</span><br><span class="line">                results.append(w)</span><br><span class="line">                input = input.data.new([top_index]).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> w == <span class="string">'&lt;EOP&gt;'</span>:</span><br><span class="line">                <span class="keyword">del</span> results[<span class="number">-1</span>]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(output, temperature)</span>:</span></span><br><span class="line">    output = F.softmax(output.to(torch.float64) / temperature)</span><br><span class="line">    <span class="comment"># output 默认是 float 32，但是 np.random.multinomial 在处理时会将数据强制转换到 float 64，会出现精度上的损失</span></span><br><span class="line">    output = output.to(<span class="string">'cpu'</span>).detach().numpy()</span><br><span class="line">    <span class="keyword">return</span> np.random.multinomial(<span class="number">1</span>, output[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">start_words = <span class="string">'雪'</span></span><br><span class="line">results = list(start_words)</span><br><span class="line">start_words_len = len(start_words)</span><br><span class="line"><span class="comment"># 第一个词语是&lt;START&gt;</span></span><br><span class="line">input = torch.Tensor([word2index[<span class="string">'&lt;START&gt;'</span>]]).view(<span class="number">1</span>, <span class="number">1</span>).long().cuda()</span><br><span class="line">hidden = <span class="literal">None</span></span><br><span class="line">model.eval()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">125</span>):</span><br><span class="line">        output, hidden = model(input, hidden)</span><br><span class="line">        <span class="comment"># 如果在给定的句首中，input为句首中的下一个字</span></span><br><span class="line">        <span class="keyword">if</span> i &lt; start_words_len:</span><br><span class="line">            w = results[i]</span><br><span class="line">            input = input.data.new([word2index[w]]).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 否则将output作为下一个input进行</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            top_index = sample(output, <span class="number">0.5</span>)</span><br><span class="line">            top_index = np.where(top_index[<span class="number">0</span>]==<span class="number">1</span>)[<span class="number">0</span>].item()</span><br><span class="line">            w = index2word[top_index]</span><br><span class="line">            results.append(w)</span><br><span class="line">            input = input.data.new([top_index]).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> w == <span class="string">'&lt;EOP&gt;'</span>:</span><br><span class="line">            <span class="keyword">del</span> results[<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">print(<span class="string">''</span>.join(results))</span><br></pre></td></tr></table></figure>

<h2 id="实验分析-2"><a href="#实验分析-2" class="headerlink" title="实验分析"></a>实验分析</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: 月</span><br><span class="line">Output: 月豺有性，近问东所。一声留夜，日起相关。</span><br></pre></td></tr></table></figure>

<p>由于采用了 softmax temperature 采样下一个预测词，并没有出现生成和训练集里面的诗歌一模一样的情况。</p>
<h1 id="电影评论情感分类"><a href="#电影评论情感分类" class="headerlink" title="电影评论情感分类"></a>电影评论情感分类</h1><h2 id="加载数据-3"><a href="#加载数据-3" class="headerlink" title="加载数据"></a>加载数据</h2><p>导入训练数据，构建 <code>MovieDataset</code>，继承于 <code>Dataset</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, path, word_vecs, word2id)</span>:</span></span><br><span class="line">        self.df = pd.read_csv(path, sep=<span class="string">'\t'</span>, header=<span class="literal">None</span>)</span><br><span class="line">        self.labels = list(self.df[<span class="number">0</span>])</span><br><span class="line">        self.sentences = list(self.df[<span class="number">1</span>])</span><br><span class="line">        self.word_vecs = word_vecs</span><br><span class="line">        self.word2id = word2id</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.df)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        label = self.labels[index]</span><br><span class="line">        sentence = self.sentences[index]</span><br><span class="line">        words = sentence.split(<span class="string">' '</span>)[:<span class="number">75</span>]</span><br><span class="line">        sentence_vec = []</span><br><span class="line">        sentence_vec = torch.zeros(<span class="number">1</span>, <span class="number">75</span>, <span class="number">50</span>)</span><br><span class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(words):</span><br><span class="line">            sentence_vec[<span class="number">0</span>][i] = torch.tensor(self.word_vecs[self.word2id[word]])</span><br><span class="line">        <span class="keyword">return</span> sentence_vec, label</span><br><span class="line"></span><br><span class="line">train_dataset = MovieDataset(<span class="string">'./dataset/train.txt'</span>, word_vecs, word2id)</span><br><span class="line">train_dataloader = DataLoader(train_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">validation_dataset = MovieDataset(<span class="string">'./dataset/validation.txt'</span>, word_vecs, word2id)</span><br><span class="line">validation_dataloader = DataLoader(train_dataset, batch_size=len(validation_dataset))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> validation_datas, validation_labels <span class="keyword">in</span> validation_dataloader:</span><br><span class="line">    validation_datas = validation_datas.cuda()</span><br><span class="line">    validation_labels = validation_labels.cuda()</span><br></pre></td></tr></table></figure>

<h2 id="加载词向量以及构建-word2index-字典"><a href="#加载词向量以及构建-word2index-字典" class="headerlink" title="加载词向量以及构建 word2index 字典"></a>加载词向量以及构建 word2index 字典</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_word2id</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param file: word2id 保存地址</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    word2id = &#123;<span class="string">'_PAD_'</span>: <span class="number">0</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> _path <span class="keyword">in</span> path:</span><br><span class="line">        <span class="keyword">with</span> open(_path, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">                sp = line.strip().split()</span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> sp[<span class="number">1</span>:]:</span><br><span class="line">                    <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> word2id.keys():</span><br><span class="line">                        word2id[word] = len(word2id)</span><br><span class="line">    <span class="keyword">return</span> word2id</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_word2vec</span><span class="params">(fname, word2id, save_to_path=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param fname: 预训练的word2vec.</span></span><br><span class="line"><span class="string">    :param word2id: 语料文本中包含的词汇集.</span></span><br><span class="line"><span class="string">    :param save_to_path: 保存训练语料库中的词组对应的word2vec到本地</span></span><br><span class="line"><span class="string">    :return: 语料文本中词汇集对应的word2vec向量&#123;id: word2vec&#125;.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n_words = max(word2id.values()) + <span class="number">1</span></span><br><span class="line">    model = gensim.models.KeyedVectors.load_word2vec_format(fname, binary=<span class="literal">True</span>)</span><br><span class="line">    word_vecs = np.array(np.random.uniform(<span class="number">-1.</span>, <span class="number">1.</span>, [n_words, model.vector_size]))</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word2id.keys():</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            word_vecs[word2id[word]] = model[word]</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">if</span> save_to_path:</span><br><span class="line">        <span class="keyword">with</span> open(save_to_path, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> vec <span class="keyword">in</span> word_vecs:</span><br><span class="line">                vec = [str(w) <span class="keyword">for</span> w <span class="keyword">in</span> vec]</span><br><span class="line">                f.write(<span class="string">' '</span>.join(vec))</span><br><span class="line">                f.write(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">return</span> word_vecs</span><br><span class="line"></span><br><span class="line">word2id = build_word2id([<span class="string">'./dataset/train.txt'</span>, <span class="string">'./dataset/validation.txt'</span>])</span><br><span class="line">word_vecs = build_word2vec(<span class="string">'./dataset/wiki_word2vec_50.bin'</span>, word2id)</span><br></pre></td></tr></table></figure>

<h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TextCNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, word_embedding_dimension, sentence_max_size, label_num)</span>:</span></span><br><span class="line">        super(TextCNN, self).__init__()</span><br><span class="line">        self.label_num = label_num</span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, (<span class="number">3</span>, word_embedding_dimension))</span><br><span class="line">        self.conv4 = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, (<span class="number">4</span>, word_embedding_dimension))</span><br><span class="line">        self.conv5 = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, (<span class="number">5</span>, word_embedding_dimension))</span><br><span class="line">        self.Max3_pool = nn.MaxPool2d((sentence_max_size<span class="number">-3</span>+<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.Max4_pool = nn.MaxPool2d((sentence_max_size<span class="number">-4</span>+<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.Max5_pool = nn.MaxPool2d((sentence_max_size<span class="number">-5</span>+<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.linear1 = nn.Linear(<span class="number">3</span>, label_num)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        batch = x.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># Convolution</span></span><br><span class="line">        x1 = F.relu(self.conv3(x))</span><br><span class="line">        x2 = F.relu(self.conv4(x))</span><br><span class="line">        x3 = F.relu(self.conv5(x))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Pooling</span></span><br><span class="line">        x1 = self.Max3_pool(x1)</span><br><span class="line">        x2 = self.Max4_pool(x2)</span><br><span class="line">        x3 = self.Max5_pool(x3)</span><br><span class="line"></span><br><span class="line">        x = torch.cat((x1, x2, x3), <span class="number">-1</span>)</span><br><span class="line">        x = x.view(batch, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        x = self.linear1(x)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.label_num)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h2 id="训练过程-3"><a href="#训练过程-3" class="headerlink" title="训练过程"></a>训练过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">batch_size=<span class="number">32</span></span><br><span class="line">epoch=<span class="number">10</span></span><br><span class="line">gpu=<span class="number">0</span></span><br><span class="line">out_channel=<span class="number">2</span></span><br><span class="line">label_num=<span class="number">2</span></span><br><span class="line">embed_dim = <span class="number">50</span></span><br><span class="line">sentence_len = <span class="number">75</span></span><br><span class="line"></span><br><span class="line">model = TextCNN(embed_dim, sentence_len, label_num)</span><br><span class="line">model = model.cuda()</span><br><span class="line"><span class="comment"># model.apply(weights_init)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>, weight_decay=<span class="number">0.0005</span>)</span><br><span class="line"></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line">loss_sum = <span class="number">0</span></span><br><span class="line">acc_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epoch):</span><br><span class="line">    <span class="keyword">for</span> datas, labels <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        datas = datas.cuda()</span><br><span class="line">        labels = labels.cuda()</span><br><span class="line"></span><br><span class="line">        outs = model(datas)</span><br><span class="line">        loss = criterion(outs, labels)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        loss_sum += loss.item()</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> count % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                validation_outs = model(validation_datas)</span><br><span class="line">                validation_loss = criterion(validation_outs, validation_labels)</span><br><span class="line">                validation_acc = (validation_outs.topk(<span class="number">1</span>)[<span class="number">1</span>].view(<span class="number">-1</span>)==validation_labels).to(torch.float).mean()</span><br><span class="line">                    </span><br><span class="line">            print(<span class="string">"Epoch: &#123;&#125; | train_loss: &#123;:.3&#125;, v_loss: &#123;:.3&#125;, v_acc: &#123;:.3&#125;"</span>.format(epoch+<span class="number">1</span>, loss_sum/<span class="number">100</span>, validation_loss, validation_acc))</span><br><span class="line">            loss_sum = <span class="number">0</span></span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            acc_sum = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h2 id="实验分析-3"><a href="#实验分析-3" class="headerlink" title="实验分析"></a>实验分析</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 8 | train_loss: 0.467, v_loss: 0.449, v_acc: 0.783</span><br><span class="line">Epoch: 8 | train_loss: 0.476, v_loss: 0.481, v_acc: 0.764</span><br><span class="line">Epoch: 8 | train_loss: 0.479, v_loss: 0.433, v_acc: 0.797</span><br><span class="line">Epoch: 8 | train_loss: 0.457, v_loss: 0.451, v_acc: 0.781</span><br><span class="line">Epoch: 8 | train_loss: 0.457, v_loss: 0.398, v_acc: 0.818</span><br></pre></td></tr></table></figure>

<p>在第 8 个 epochs 的时候，在验证机上的准确率达到了 80%。textcnn 虽然说训练速度快，但是效果相比于 LSTM 较弱。</p>
</div><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_dd" href="https://www.addtoany.com/share"></a><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_telegram"></a><a class="a2a_button_whatsapp"></a><a class="a2a_button_reddit"></a></div><script src="https://static.addtoany.com/menu/page.js" defer></script></article></div><!--!--><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><script src="https://utteranc.es/client.js" repo="zhangxu3486432/zhangxu3486432.github.io" issue-term="og:title" label="comment" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200723205110.webp" alt="搞互联网的"></figure><p class="title is-size-4 is-block line-height-inherit">搞互联网的</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>北京</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">15</p></a></div></div></nav><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zhangxu3486432"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="微博" href="https://weibo.com/u/6812563745"><i class="fab fa-weibo"></i></a></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><a class="media-left" href="/tutorial/postgresql-backup/"><p class="image is-64x64"><img class="thumbnail" src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200731000222.svg" alt="postgresql_backup"></p></a><div class="media-content size-small"><p><time dateTime="2020-07-30T11:37:00.000Z">2020-07-30</time></p><p class="title is-6"><a class="link-muted" href="/tutorial/postgresql-backup/">postgresql_backup</a></p><p class="is-uppercase"></p></div></article><article class="media"><a class="media-left" href="/tutorial/elasticsearch/"><p class="image is-64x64"><img class="thumbnail" src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200729152453.svg" alt="elasticsearch"></p></a><div class="media-content size-small"><p><time dateTime="2020-07-29T07:18:20.000Z">2020-07-29</time></p><p class="title is-6"><a class="link-muted" href="/tutorial/elasticsearch/">elasticsearch</a></p><p class="is-uppercase"></p></div></article><article class="media"><a class="media-left" href="/tutorial/git/"><p class="image is-64x64"><img class="thumbnail" src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200724235431.png" alt="Git"></p></a><div class="media-content size-small"><p><time dateTime="2020-07-24T15:52:29.000Z">2020-07-24</time></p><p class="title is-6"><a class="link-muted" href="/tutorial/git/">Git</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%95%99%E7%A8%8B/">教程</a> / <a class="link-muted" href="/categories/%E6%95%99%E7%A8%8B/git/">git</a></p></div></article><article class="media"><a class="media-left" href="/bug/PostgreSQL%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE/"><p class="image is-64x64"><img class="thumbnail" src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/elephant.png" alt="PostgreSQL 迁移数据"></p></a><div class="media-content size-small"><p><time dateTime="2020-07-23T08:07:27.000Z">2020-07-23</time></p><p class="title is-6"><a class="link-muted" href="/bug/PostgreSQL%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE/">PostgreSQL 迁移数据</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a> / <a class="link-muted" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/">PostgreSQL</a></p></div></article><article class="media"><a class="media-left" href="/tutorial/docker-timezone/"><p class="image is-64x64"><img class="thumbnail" src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200725085035.svg" alt="Docker 设置时区"></p></a><div class="media-content size-small"><p><time dateTime="2020-02-21T14:30:29.000Z">2020-02-21</time></p><p class="title is-6"><a class="link-muted" href="/tutorial/docker-timezone/">Docker 设置时区</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%95%99%E7%A8%8B/">教程</a> / <a class="link-muted" href="/categories/%E6%95%99%E7%A8%8B/Docker/">Docker</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">开源项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%99%E7%A8%8B/"><span class="level-start"><span class="level-item">教程</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%99%E7%A8%8B/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%99%E7%A8%8B/git/"><span class="level-start"><span class="level-item">git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%99%E7%A8%8B/%E5%8D%9A%E5%AE%A2%E5%BC%80%E5%8F%91/"><span class="level-start"><span class="level-item">博客开发</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="level-start"><span class="level-item">数据库</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/"><span class="level-start"><span class="level-item">PostgreSQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%9D%82%E8%AE%B0/"><span class="level-start"><span class="level-item">杂记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%BA%E6%96%87/"><span class="level-start"><span class="level-item">论文</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%BA%E6%96%87/%E5%9F%8E%E5%B8%82%E8%AE%A1%E7%AE%97/"><span class="level-start"><span class="level-item">城市计算</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Bug/"><span class="tag">Bug</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PostgreSQL/"><span class="tag">PostgreSQL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/blog/"><span class="tag">blog</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/icarus/"><span class="tag">icarus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tutorial/"><span class="tag">tutorial</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6/"><span class="tag">中国科学院大学</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9F%8E%E5%B8%82%E8%AE%A1%E7%AE%97/"><span class="tag">城市计算</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"><span class="tag">异常检测</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">数据库</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%8E%B0%E4%BB%A3%E8%AF%97/"><span class="tag">现代诗</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%BC%E8%BF%B0/"><span class="tag">综述</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87/"><span class="tag">论文</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://cdn.jsdelivr.net/gh/zhangxu3486432/static/image/20200723204234.svg" alt="彩虹的情诗" height="28"></a><p class="size-small"><span>&copy; 2020 张旭</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zhangxu3486432/"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://blog.adream.win',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>